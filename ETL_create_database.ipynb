{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luispsalazar/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add the clean movie function that takes in the argument, \"movie\".\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie)\n",
    "    alt_titles = {}\n",
    "\n",
    "    # combine alternate titles into one list\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        if key in movie:\n",
    "            alt_titles[key] = movie[key]\n",
    "            movie.pop(key)\n",
    "    if len(alt_titles) > 0:\n",
    "        movie['alt_titles'] = alt_titles\n",
    "\n",
    "    # merge column names\n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "\n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Add the function that takes in three arguments;\n",
    "# Wikipedia data, Kaggle metadata, and MovieLens rating data (from Kaggle)\n",
    "\n",
    "def extract_transform_load():\n",
    "    # Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\n",
    "    kaggle_metadata = pd.read_csv(kaggle_file, low_memory=False)\n",
    "    ratings = pd.read_csv(f'{file_dir}ratings.csv')\n",
    "\n",
    "    # Open and read the Wikipedia data JSON file.\n",
    "    with open(f'{file_dir}/wikipedia-movies.json', mode='r') as file:\n",
    "        wiki_movies_raw = json.load(file)\n",
    "    \n",
    "    # Write a list comprehension to filter out TV shows.\n",
    "    wiki_movies = [movie for movie in wiki_movies_raw\n",
    "               if ('Director' in movie or 'Directed by' in movie)\n",
    "                   and 'imdb_link' in movie\n",
    "                   and 'No. of episodes' not in movie]\n",
    "\n",
    "    # (Step 4) Write a list comprehension to iterate through the cleaned wiki movies list\n",
    "    # and call the clean_movie function on each movie.\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "\n",
    "    # Read in the cleaned movies list from Step 4 as a DataFrame.\n",
    "    wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "\n",
    "    # Write a try-except block to catch errors while extracting the IMDb ID using a regular expression string and\n",
    "    # dropping any imdb_id duplicates. If there is an error, capture and print the exception.\n",
    "    try:\n",
    "        wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "        wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "    except Exception as e:\n",
    "        print(e) \n",
    "\n",
    "    #  Write a list comprehension to keep the columns that don't have null values from the wiki_movies_df DataFrame.\n",
    "    wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "    wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
    "\n",
    "    # (Step # 8) Create a variable that will hold the non-null values from the “Box office” column.\n",
    "    box_office = wiki_movies_df['Box office'].dropna()\n",
    "    \n",
    "    # Convert the box office data created in Step 8 to string values using the lambda and join functions.\n",
    "    box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "    # Write a regular expression to match the six elements of \"form_one\" of the box office data.\n",
    "    form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\n",
    "                    \n",
    "    # Write a regular expression to match the three elements of \"form_two\" of the box office data.\n",
    "    form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
    "    box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "    box_office.str.extract(f'({form_one}|{form_two})')\n",
    "\n",
    "    # Add the parse_dollars function.\n",
    "    def parse_dollars(s):\n",
    "        # if s is not a string, return NaN\n",
    "        if type(s) != str:\n",
    "            return np.nan\n",
    "        # if input is of the form $###.# million\n",
    "        if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "            # remove dollar sign and \" million\"\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "            # convert to float and multiply by a million\n",
    "            value = float(s) * 10**6\n",
    "            # return value\n",
    "            return value\n",
    "        # if input is of the form $###.# billion\n",
    "        elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "            # remove dollar sign and \" billion\"\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "            # convert to float and multiply by a billion\n",
    "            value = float(s) * 10**9\n",
    "            # return value\n",
    "            return value\n",
    "        # if input is of the form $###,###,###\n",
    "        elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "            # remove dollar sign and commas\n",
    "            s = re.sub('\\$|,','', s)\n",
    "            # convert to float\n",
    "            value = float(s)\n",
    "            # return value\n",
    "            return value\n",
    "        # otherwise, return NaN\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    # Clean the box office column in the wiki_movies_df DataFrame.\n",
    "    wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    wiki_movies_df.drop('Box office', axis=1, inplace=True) # check this\n",
    "    \n",
    "    # Clean the budget column in the wiki_movies_df DataFrame.\n",
    "    budget = wiki_movies_df['Budget'].dropna()\n",
    "    budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "    wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "\n",
    "    # Clean the release date column in the wiki_movies_df DataFrame.\n",
    "    release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]\\d,\\s\\d{4}'\n",
    "    date_form_two = r'\\d{4}.[01]\\d.[123]\\d'\n",
    "    date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "    date_form_four = r'\\d{4}'\n",
    "    wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)\n",
    "\n",
    "    # Clean the running time column in the wiki_movies_df DataFrame.\n",
    "    running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "    running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "    wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
    "    wiki_movies_df.drop('Running time', axis=1, inplace=True)\n",
    "     \n",
    "    # 2. Clean the Kaggle metadata.\n",
    "    kaggle_metadata[~kaggle_metadata['adult'].isin(['True','False'])]\n",
    "    kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')\n",
    "    kaggle_metadata['video'] == 'True'\n",
    "    kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'\n",
    "    kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
    "    kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')\n",
    "    kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')\n",
    "    kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])\n",
    "    pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "    ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "    \n",
    "    # 3. Merge the two DataFrames into the movies DataFrame.\n",
    "    movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle'])\n",
    "\n",
    "    # 4. Drop unnecessary columns from the merged DataFrame.\n",
    "    movies_df['original_language'].apply(lambda x: tuple(x) if type(x) == list else x).value_counts(dropna=False)\n",
    "    movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)\n",
    "\n",
    "    # 5. Add in the function to fill in the missing Kaggle data.\n",
    "    def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "        df[kaggle_column] = df.apply(\n",
    "            lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column]\n",
    "            , axis=1)\n",
    "        df.drop(columns=wiki_column, inplace=True)\n",
    "\n",
    "    # 6. Call the function in Step 5 with the DataFrame and columns as the arguments.\n",
    "    fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "    fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "    fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "    movies_df\n",
    "\n",
    "    # 7. Filter the movies DataFrame for specific columns.\n",
    "    for col in movies_df.columns:\n",
    "        lists_to_tuples = lambda x: tuple(x) if type(x) == list else x\n",
    "        value_counts = movies_df[col].apply(lists_to_tuples).value_counts(dropna=False)\n",
    "        num_values = len(value_counts)\n",
    "\n",
    "    movies_df['video'].value_counts(dropna=False)\n",
    "    \n",
    "    movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                       'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                       'genres','original_language','overview','spoken_languages','Country',\n",
    "                       'production_companies','production_countries','Distributor',\n",
    "                       'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                      ]]\n",
    "\n",
    "    # 8. Rename the columns in the movies DataFrame.\n",
    "    movies_df.rename({'id':'kaggle_id',\n",
    "                  'title_kaggle':'title',\n",
    "                  'url':'wikipedia_url',\n",
    "                  'budget_kaggle':'budget',\n",
    "                  'release_date_kaggle':'release_date',\n",
    "                  'Country':'country',\n",
    "                  'Distributor':'distributor',\n",
    "                  'Producer(s)':'producers',\n",
    "                  'Director':'director',\n",
    "                  'Starring':'starring',\n",
    "                  'Cinematography':'cinematography',\n",
    "                  'Editor(s)':'editors',\n",
    "                  'Writer(s)':'writers',\n",
    "                  'Composer(s)':'composers',\n",
    "                  'Based on':'based_on'\n",
    "                 }, axis='columns', inplace=True)\n",
    "\n",
    "    # 9. Transform and merge the ratings DataFrame.\n",
    "    rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "                .rename({'userId':'count'}, axis=1) \\\n",
    "                .pivot(index='movieId',columns='rating', values='count')\n",
    "    rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "    \n",
    "    movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')\n",
    "    \n",
    "    movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)\n",
    "    \n",
    "    \"postgresql+psycopg2://[user]:[password]@[location]:[port]/[database]\"\n",
    "    db_string = f\"postgresql+psycopg2://postgres:{db_password}@127.0.0.1:5432/movie_data\"\n",
    "    engine = create_engine(db_string)\n",
    "    movies_df.to_sql(name='movies', con=engine, if_exists='replace', method='multi')\n",
    "    \n",
    "    # DELETE THE TABLE \"RATINGS\" IN PGADMIN 4 (SQL) BEFORE RUNNING THIS LINE, BECAUSE OTHERWISE\n",
    "    # THE EXISTING TABLE WILL GET LARGER WITH THIS RUN (APPEND), NOT REPLACE LIKE ABOVE\n",
    "\n",
    "    rows_imported = 0\n",
    "\n",
    "    # get the start_time from time.time()\n",
    "    start_time = time.time()\n",
    "\n",
    "    for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=100000):\n",
    "        print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "        data.to_sql(name='ratings', con=engine, if_exists='append', method = 'multi')\n",
    "        rows_imported += len(data)\n",
    "\n",
    "        # add elapsed time to final print out\n",
    "        print(f'Done. {time.time() - start_time} total seconds elapsed')\n",
    "        \n",
    "    return wiki_movies_df, movies_with_ratings_df, movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create the path to your file directory and variables for the three files.\n",
    "file_dir = '/Users/luispsalazar/Desktop/Movies_ETL/'\n",
    "\n",
    "# The Wikipedia data\n",
    "wiki_file = f'{file_dir}/wikipedia_movies.json'\n",
    "\n",
    "# The Kaggle metadata\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "\n",
    "# The MovieLens rating data.\n",
    "ratings_file = f'{file_dir}/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 100000...Done. 19.493232250213623 total seconds elapsed\n",
      "importing rows 100000 to 200000...Done. 38.45161294937134 total seconds elapsed\n",
      "importing rows 200000 to 300000...Done. 57.92339015007019 total seconds elapsed\n",
      "importing rows 300000 to 400000...Done. 77.3668532371521 total seconds elapsed\n",
      "importing rows 400000 to 500000...Done. 96.59556007385254 total seconds elapsed\n",
      "importing rows 500000 to 600000...Done. 116.13870596885681 total seconds elapsed\n",
      "importing rows 600000 to 700000...Done. 135.3864462375641 total seconds elapsed\n",
      "importing rows 700000 to 800000...Done. 154.61346411705017 total seconds elapsed\n",
      "importing rows 800000 to 900000...Done. 174.26804614067078 total seconds elapsed\n",
      "importing rows 900000 to 1000000...Done. 193.45900917053223 total seconds elapsed\n",
      "importing rows 1000000 to 1100000...Done. 212.8259551525116 total seconds elapsed\n",
      "importing rows 1100000 to 1200000...Done. 233.68532729148865 total seconds elapsed\n",
      "importing rows 1200000 to 1300000...Done. 253.20907616615295 total seconds elapsed\n",
      "importing rows 1300000 to 1400000...Done. 272.3888692855835 total seconds elapsed\n",
      "importing rows 1400000 to 1500000...Done. 291.83597230911255 total seconds elapsed\n",
      "importing rows 1500000 to 1600000...Done. 311.171245098114 total seconds elapsed\n",
      "importing rows 1600000 to 1700000...Done. 330.463858127594 total seconds elapsed\n",
      "importing rows 1700000 to 1800000...Done. 349.6400582790375 total seconds elapsed\n",
      "importing rows 1800000 to 1900000...Done. 368.8559491634369 total seconds elapsed\n",
      "importing rows 1900000 to 2000000...Done. 388.26255106925964 total seconds elapsed\n",
      "importing rows 2000000 to 2100000...Done. 407.5671181678772 total seconds elapsed\n",
      "importing rows 2100000 to 2200000...Done. 426.91645908355713 total seconds elapsed\n",
      "importing rows 2200000 to 2300000...Done. 446.19354701042175 total seconds elapsed\n",
      "importing rows 2300000 to 2400000...Done. 465.4538631439209 total seconds elapsed\n",
      "importing rows 2400000 to 2500000...Done. 484.57437920570374 total seconds elapsed\n",
      "importing rows 2500000 to 2600000...Done. 503.85965514183044 total seconds elapsed\n",
      "importing rows 2600000 to 2700000...Done. 523.3072981834412 total seconds elapsed\n",
      "importing rows 2700000 to 2800000...Done. 542.6450071334839 total seconds elapsed\n",
      "importing rows 2800000 to 2900000...Done. 562.2655420303345 total seconds elapsed\n",
      "importing rows 2900000 to 3000000...Done. 581.8243861198425 total seconds elapsed\n",
      "importing rows 3000000 to 3100000...Done. 600.9905202388763 total seconds elapsed\n",
      "importing rows 3100000 to 3200000...Done. 620.3924422264099 total seconds elapsed\n",
      "importing rows 3200000 to 3300000...Done. 639.8718132972717 total seconds elapsed\n",
      "importing rows 3300000 to 3400000...Done. 659.2049112319946 total seconds elapsed\n",
      "importing rows 3400000 to 3500000...Done. 678.486976146698 total seconds elapsed\n",
      "importing rows 3500000 to 3600000...Done. 697.5061161518097 total seconds elapsed\n",
      "importing rows 3600000 to 3700000...Done. 717.1461882591248 total seconds elapsed\n",
      "importing rows 3700000 to 3800000...Done. 736.487181186676 total seconds elapsed\n",
      "importing rows 3800000 to 3900000...Done. 755.8661570549011 total seconds elapsed\n",
      "importing rows 3900000 to 4000000...Done. 775.2641201019287 total seconds elapsed\n",
      "importing rows 4000000 to 4100000...Done. 794.495637178421 total seconds elapsed\n",
      "importing rows 4100000 to 4200000...Done. 813.7976841926575 total seconds elapsed\n",
      "importing rows 4200000 to 4300000...Done. 833.329567193985 total seconds elapsed\n",
      "importing rows 4300000 to 4400000...Done. 852.7600121498108 total seconds elapsed\n",
      "importing rows 4400000 to 4500000...Done. 872.1605021953583 total seconds elapsed\n",
      "importing rows 4500000 to 4600000...Done. 891.6873118877411 total seconds elapsed\n",
      "importing rows 4600000 to 4700000...Done. 910.9014322757721 total seconds elapsed\n",
      "importing rows 4700000 to 4800000...Done. 930.5198640823364 total seconds elapsed\n",
      "importing rows 4800000 to 4900000...Done. 949.976902961731 total seconds elapsed\n",
      "importing rows 4900000 to 5000000...Done. 969.7356810569763 total seconds elapsed\n",
      "importing rows 5000000 to 5100000...Done. 989.852771282196 total seconds elapsed\n",
      "importing rows 5100000 to 5200000...Done. 1011.6662271022797 total seconds elapsed\n",
      "importing rows 5200000 to 5300000...Done. 1031.7713239192963 total seconds elapsed\n",
      "importing rows 5300000 to 5400000...Done. 1051.812271118164 total seconds elapsed\n",
      "importing rows 5400000 to 5500000...Done. 1071.98423910141 total seconds elapsed\n",
      "importing rows 5500000 to 5600000...Done. 1092.2762398719788 total seconds elapsed\n",
      "importing rows 5600000 to 5700000...Done. 1112.575942993164 total seconds elapsed\n",
      "importing rows 5700000 to 5800000...Done. 1132.8122291564941 total seconds elapsed\n",
      "importing rows 5800000 to 5900000...Done. 1153.1528489589691 total seconds elapsed\n",
      "importing rows 5900000 to 6000000...Done. 1173.3691370487213 total seconds elapsed\n",
      "importing rows 6000000 to 6100000...Done. 1193.5279660224915 total seconds elapsed\n",
      "importing rows 6100000 to 6200000...Done. 1213.7950139045715 total seconds elapsed\n",
      "importing rows 6200000 to 6300000...Done. 1234.1258671283722 total seconds elapsed\n",
      "importing rows 6300000 to 6400000...Done. 1254.5705542564392 total seconds elapsed\n",
      "importing rows 6400000 to 6500000...Done. 1274.8658850193024 total seconds elapsed\n",
      "importing rows 6500000 to 6600000...Done. 1294.9505541324615 total seconds elapsed\n",
      "importing rows 6600000 to 6700000...Done. 1315.264477968216 total seconds elapsed\n",
      "importing rows 6700000 to 6800000...Done. 1335.6139709949493 total seconds elapsed\n",
      "importing rows 6800000 to 6900000...Done. 1353.95418715477 total seconds elapsed\n",
      "importing rows 6900000 to 7000000...Done. 1372.2517251968384 total seconds elapsed\n",
      "importing rows 7000000 to 7100000...Done. 1390.671203136444 total seconds elapsed\n",
      "importing rows 7100000 to 7200000...Done. 1408.9664342403412 total seconds elapsed\n",
      "importing rows 7200000 to 7300000...Done. 1427.6184782981873 total seconds elapsed\n",
      "importing rows 7300000 to 7400000...Done. 1446.0192122459412 total seconds elapsed\n",
      "importing rows 7400000 to 7500000...Done. 1464.3890450000763 total seconds elapsed\n",
      "importing rows 7500000 to 7600000...Done. 1482.765379190445 total seconds elapsed\n",
      "importing rows 7600000 to 7700000...Done. 1501.2318532466888 total seconds elapsed\n",
      "importing rows 7700000 to 7800000...Done. 1519.5772001743317 total seconds elapsed\n",
      "importing rows 7800000 to 7900000...Done. 1537.9602990150452 total seconds elapsed\n",
      "importing rows 7900000 to 8000000...Done. 1556.3944551944733 total seconds elapsed\n",
      "importing rows 8000000 to 8100000...Done. 1574.806176185608 total seconds elapsed\n",
      "importing rows 8100000 to 8200000...Done. 1593.1626591682434 total seconds elapsed\n",
      "importing rows 8200000 to 8300000...Done. 1611.4357390403748 total seconds elapsed\n",
      "importing rows 8300000 to 8400000...Done. 1629.908366203308 total seconds elapsed\n",
      "importing rows 8400000 to 8500000...Done. 1648.5449922084808 total seconds elapsed\n",
      "importing rows 8500000 to 8600000...Done. 1667.2064800262451 total seconds elapsed\n",
      "importing rows 8600000 to 8700000...Done. 1685.4843010902405 total seconds elapsed\n",
      "importing rows 8700000 to 8800000...Done. 1703.8753862380981 total seconds elapsed\n",
      "importing rows 8800000 to 8900000...Done. 1722.2594420909882 total seconds elapsed\n",
      "importing rows 8900000 to 9000000...Done. 1740.6058521270752 total seconds elapsed\n",
      "importing rows 9000000 to 9100000...Done. 1758.9704620838165 total seconds elapsed\n",
      "importing rows 9100000 to 9200000...Done. 1777.3863801956177 total seconds elapsed\n",
      "importing rows 9200000 to 9300000...Done. 1795.8373272418976 total seconds elapsed\n",
      "importing rows 9300000 to 9400000...Done. 1814.4124901294708 total seconds elapsed\n",
      "importing rows 9400000 to 9500000...Done. 1832.3857111930847 total seconds elapsed\n",
      "importing rows 9500000 to 9600000...Done. 1850.3178460597992 total seconds elapsed\n",
      "importing rows 9600000 to 9700000...Done. 1868.1291511058807 total seconds elapsed\n",
      "importing rows 9700000 to 9800000...Done. 1888.440369129181 total seconds elapsed\n",
      "importing rows 9800000 to 9900000...Done. 1907.4568421840668 total seconds elapsed\n",
      "importing rows 9900000 to 10000000...Done. 1926.2567822933197 total seconds elapsed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 10000000 to 10100000...Done. 1947.958113193512 total seconds elapsed\n",
      "importing rows 10100000 to 10200000...Done. 1970.0261781215668 total seconds elapsed\n",
      "importing rows 10200000 to 10300000...Done. 1990.6588380336761 total seconds elapsed\n",
      "importing rows 10300000 to 10400000...Done. 2011.3083732128143 total seconds elapsed\n",
      "importing rows 10400000 to 10500000...Done. 2033.231266260147 total seconds elapsed\n",
      "importing rows 10500000 to 10600000...Done. 2056.2452821731567 total seconds elapsed\n",
      "importing rows 10600000 to 10700000...Done. 2077.411106109619 total seconds elapsed\n",
      "importing rows 10700000 to 10800000...Done. 2097.879080057144 total seconds elapsed\n",
      "importing rows 10800000 to 10900000...Done. 2118.7143502235413 total seconds elapsed\n",
      "importing rows 10900000 to 11000000...Done. 2140.5193560123444 total seconds elapsed\n",
      "importing rows 11000000 to 11100000...Done. 2162.6802501678467 total seconds elapsed\n",
      "importing rows 11100000 to 11200000...Done. 2183.6570110321045 total seconds elapsed\n",
      "importing rows 11200000 to 11300000...Done. 2205.386960029602 total seconds elapsed\n",
      "importing rows 11300000 to 11400000...Done. 2226.120653152466 total seconds elapsed\n",
      "importing rows 11400000 to 11500000...Done. 2244.6745760440826 total seconds elapsed\n",
      "importing rows 11500000 to 11600000...Done. 2263.0418910980225 total seconds elapsed\n",
      "importing rows 11600000 to 11700000...Done. 2281.3236260414124 total seconds elapsed\n",
      "importing rows 11700000 to 11800000...Done. 2299.586617231369 total seconds elapsed\n",
      "importing rows 11800000 to 11900000...Done. 2317.8316009044647 total seconds elapsed\n",
      "importing rows 11900000 to 12000000...Done. 2336.1108391284943 total seconds elapsed\n",
      "importing rows 12000000 to 12100000...Done. 2354.415685892105 total seconds elapsed\n",
      "importing rows 12100000 to 12200000...Done. 2372.5642352104187 total seconds elapsed\n",
      "importing rows 12200000 to 12300000...Done. 2390.910891056061 total seconds elapsed\n",
      "importing rows 12300000 to 12400000...Done. 2409.4033601284027 total seconds elapsed\n",
      "importing rows 12400000 to 12500000...Done. 2427.808042049408 total seconds elapsed\n",
      "importing rows 12500000 to 12600000...Done. 2446.1869220733643 total seconds elapsed\n",
      "importing rows 12600000 to 12700000...Done. 2464.5834681987762 total seconds elapsed\n",
      "importing rows 12700000 to 12800000...Done. 2483.378744125366 total seconds elapsed\n",
      "importing rows 12800000 to 12900000...Done. 2501.4349172115326 total seconds elapsed\n",
      "importing rows 12900000 to 13000000...Done. 2519.275054216385 total seconds elapsed\n",
      "importing rows 13000000 to 13100000...Done. 2537.227035999298 total seconds elapsed\n",
      "importing rows 13100000 to 13200000...Done. 2555.143357038498 total seconds elapsed\n",
      "importing rows 13200000 to 13300000...Done. 2573.005716085434 total seconds elapsed\n",
      "importing rows 13300000 to 13400000...Done. 2590.777892112732 total seconds elapsed\n",
      "importing rows 13400000 to 13500000...Done. 2608.626160144806 total seconds elapsed\n",
      "importing rows 13500000 to 13600000...Done. 2626.5176861286163 total seconds elapsed\n",
      "importing rows 13600000 to 13700000...Done. 2644.426516056061 total seconds elapsed\n",
      "importing rows 13700000 to 13800000...Done. 2662.6888620853424 total seconds elapsed\n",
      "importing rows 13800000 to 13900000...Done. 2680.8567612171173 total seconds elapsed\n",
      "importing rows 13900000 to 14000000...Done. 2698.7816700935364 total seconds elapsed\n",
      "importing rows 14000000 to 14100000...Done. 2716.5657160282135 total seconds elapsed\n",
      "importing rows 14100000 to 14200000...Done. 2734.3790612220764 total seconds elapsed\n",
      "importing rows 14200000 to 14300000...Done. 2752.3909389972687 total seconds elapsed\n",
      "importing rows 14300000 to 14400000...Done. 2770.587681055069 total seconds elapsed\n",
      "importing rows 14400000 to 14500000...Done. 2788.414042234421 total seconds elapsed\n",
      "importing rows 14500000 to 14600000...Done. 2806.090870141983 total seconds elapsed\n",
      "importing rows 14600000 to 14700000...Done. 2823.8312849998474 total seconds elapsed\n",
      "importing rows 14700000 to 14800000...Done. 2841.5251631736755 total seconds elapsed\n",
      "importing rows 14800000 to 14900000...Done. 2859.089916944504 total seconds elapsed\n",
      "importing rows 14900000 to 15000000...Done. 2876.8142940998077 total seconds elapsed\n",
      "importing rows 15000000 to 15100000...Done. 2894.399517059326 total seconds elapsed\n",
      "importing rows 15100000 to 15200000...Done. 2912.0242261886597 total seconds elapsed\n",
      "importing rows 15200000 to 15300000...Done. 2929.7577443122864 total seconds elapsed\n",
      "importing rows 15300000 to 15400000...Done. 2947.409517288208 total seconds elapsed\n",
      "importing rows 15400000 to 15500000...Done. 2965.1877291202545 total seconds elapsed\n",
      "importing rows 15500000 to 15600000...Done. 2982.9438140392303 total seconds elapsed\n",
      "importing rows 15600000 to 15700000...Done. 3000.699415206909 total seconds elapsed\n",
      "importing rows 15700000 to 15800000...Done. 3018.463061094284 total seconds elapsed\n",
      "importing rows 15800000 to 15900000...Done. 3036.2350132465363 total seconds elapsed\n",
      "importing rows 15900000 to 16000000...Done. 3054.0141241550446 total seconds elapsed\n",
      "importing rows 16000000 to 16100000...Done. 3071.7903361320496 total seconds elapsed\n",
      "importing rows 16100000 to 16200000...Done. 3089.498825073242 total seconds elapsed\n",
      "importing rows 16200000 to 16300000...Done. 3107.3801012039185 total seconds elapsed\n",
      "importing rows 16300000 to 16400000...Done. 3125.114758014679 total seconds elapsed\n",
      "importing rows 16400000 to 16500000...Done. 3142.9574842453003 total seconds elapsed\n",
      "importing rows 16500000 to 16600000...Done. 3161.0032031536102 total seconds elapsed\n",
      "importing rows 16600000 to 16700000...Done. 3178.7269949913025 total seconds elapsed\n",
      "importing rows 16700000 to 16800000...Done. 3196.5221021175385 total seconds elapsed\n",
      "importing rows 16800000 to 16900000...Done. 3214.0883181095123 total seconds elapsed\n",
      "importing rows 16900000 to 17000000...Done. 3231.6756501197815 total seconds elapsed\n",
      "importing rows 17000000 to 17100000...Done. 3249.2539761066437 total seconds elapsed\n",
      "importing rows 17100000 to 17200000...Done. 3266.8825359344482 total seconds elapsed\n",
      "importing rows 17200000 to 17300000...Done. 3284.5718669891357 total seconds elapsed\n",
      "importing rows 17300000 to 17400000...Done. 3302.1821191310883 total seconds elapsed\n",
      "importing rows 17400000 to 17500000...Done. 3319.8006620407104 total seconds elapsed\n",
      "importing rows 17500000 to 17600000...Done. 3337.9257459640503 total seconds elapsed\n",
      "importing rows 17600000 to 17700000...Done. 3355.799232006073 total seconds elapsed\n",
      "importing rows 17700000 to 17800000...Done. 3373.3113181591034 total seconds elapsed\n",
      "importing rows 17800000 to 17900000...Done. 3390.882328271866 total seconds elapsed\n",
      "importing rows 17900000 to 18000000...Done. 3408.4656760692596 total seconds elapsed\n",
      "importing rows 18000000 to 18100000...Done. 3426.1064162254333 total seconds elapsed\n",
      "importing rows 18100000 to 18200000...Done. 3443.6866121292114 total seconds elapsed\n",
      "importing rows 18200000 to 18300000...Done. 3461.258994102478 total seconds elapsed\n",
      "importing rows 18300000 to 18400000...Done. 3478.8146970272064 total seconds elapsed\n",
      "importing rows 18400000 to 18500000...Done. 3496.428150177002 total seconds elapsed\n",
      "importing rows 18500000 to 18600000...Done. 3514.037942171097 total seconds elapsed\n",
      "importing rows 18600000 to 18700000...Done. 3531.6274530887604 total seconds elapsed\n",
      "importing rows 18700000 to 18800000...Done. 3549.2479412555695 total seconds elapsed\n",
      "importing rows 18800000 to 18900000...Done. 3566.9906001091003 total seconds elapsed\n",
      "importing rows 18900000 to 19000000...Done. 3584.6348140239716 total seconds elapsed\n",
      "importing rows 19000000 to 19100000...Done. 3602.25133228302 total seconds elapsed\n",
      "importing rows 19100000 to 19200000...Done. 3619.9571900367737 total seconds elapsed\n",
      "importing rows 19200000 to 19300000...Done. 3637.54053401947 total seconds elapsed\n",
      "importing rows 19300000 to 19400000...Done. 3655.337238073349 total seconds elapsed\n",
      "importing rows 19400000 to 19500000...Done. 3672.9936871528625 total seconds elapsed\n",
      "importing rows 19500000 to 19600000...Done. 3690.723724126816 total seconds elapsed\n",
      "importing rows 19600000 to 19700000...Done. 3708.522803068161 total seconds elapsed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 19700000 to 19800000...Done. 3726.1001360416412 total seconds elapsed\n",
      "importing rows 19800000 to 19900000...Done. 3743.756702184677 total seconds elapsed\n",
      "importing rows 19900000 to 20000000...Done. 3761.404818058014 total seconds elapsed\n",
      "importing rows 20000000 to 20100000...Done. 3779.120663166046 total seconds elapsed\n",
      "importing rows 20100000 to 20200000...Done. 3796.7974910736084 total seconds elapsed\n",
      "importing rows 20200000 to 20300000...Done. 3814.431177139282 total seconds elapsed\n",
      "importing rows 20300000 to 20400000...Done. 3832.3655121326447 total seconds elapsed\n",
      "importing rows 20400000 to 20500000...Done. 3850.1414029598236 total seconds elapsed\n",
      "importing rows 20500000 to 20600000...Done. 3867.783809185028 total seconds elapsed\n",
      "importing rows 20600000 to 20700000...Done. 3885.4373190402985 total seconds elapsed\n",
      "importing rows 20700000 to 20800000...Done. 3903.040552139282 total seconds elapsed\n",
      "importing rows 20800000 to 20900000...Done. 3920.820367336273 total seconds elapsed\n",
      "importing rows 20900000 to 21000000...Done. 3938.514995098114 total seconds elapsed\n",
      "importing rows 21000000 to 21100000...Done. 3956.250566959381 total seconds elapsed\n",
      "importing rows 21100000 to 21200000...Done. 3973.89887714386 total seconds elapsed\n",
      "importing rows 21200000 to 21300000...Done. 3991.495045900345 total seconds elapsed\n",
      "importing rows 21300000 to 21400000...Done. 4009.482702255249 total seconds elapsed\n",
      "importing rows 21400000 to 21500000...Done. 4027.055804014206 total seconds elapsed\n",
      "importing rows 21500000 to 21600000...Done. 4044.5906372070312 total seconds elapsed\n",
      "importing rows 21600000 to 21700000...Done. 4062.1495411396027 total seconds elapsed\n",
      "importing rows 21700000 to 21800000...Done. 4079.6742169857025 total seconds elapsed\n",
      "importing rows 21800000 to 21900000...Done. 4097.317626237869 total seconds elapsed\n",
      "importing rows 21900000 to 22000000...Done. 4114.896440267563 total seconds elapsed\n",
      "importing rows 22000000 to 22100000...Done. 4132.597843170166 total seconds elapsed\n",
      "importing rows 22100000 to 22200000...Done. 4150.553550243378 total seconds elapsed\n",
      "importing rows 22200000 to 22300000...Done. 4168.1202890872955 total seconds elapsed\n",
      "importing rows 22300000 to 22400000...Done. 4185.855077981949 total seconds elapsed\n",
      "importing rows 22400000 to 22500000...Done. 4203.488534212112 total seconds elapsed\n",
      "importing rows 22500000 to 22600000...Done. 4221.105317115784 total seconds elapsed\n",
      "importing rows 22600000 to 22700000...Done. 4238.723824262619 total seconds elapsed\n",
      "importing rows 22700000 to 22800000...Done. 4256.430838108063 total seconds elapsed\n",
      "importing rows 22800000 to 22900000...Done. 4277.049680948257 total seconds elapsed\n",
      "importing rows 22900000 to 23000000...Done. 4297.857762098312 total seconds elapsed\n",
      "importing rows 23000000 to 23100000...Done. 4318.341861963272 total seconds elapsed\n",
      "importing rows 23100000 to 23200000...Done. 4338.5357320308685 total seconds elapsed\n",
      "importing rows 23200000 to 23300000...Done. 4358.839792251587 total seconds elapsed\n",
      "importing rows 23300000 to 23400000...Done. 4379.613699197769 total seconds elapsed\n",
      "importing rows 23400000 to 23500000...Done. 4399.925505161285 total seconds elapsed\n",
      "importing rows 23500000 to 23600000...Done. 4422.20919418335 total seconds elapsed\n",
      "importing rows 23600000 to 23700000...Done. 4441.926960945129 total seconds elapsed\n",
      "importing rows 23700000 to 23800000...Done. 4461.621598005295 total seconds elapsed\n",
      "importing rows 23800000 to 23900000...Done. 4481.376955986023 total seconds elapsed\n",
      "importing rows 23900000 to 24000000...Done. 4501.167070150375 total seconds elapsed\n",
      "importing rows 24000000 to 24100000...Done. 4520.862475156784 total seconds elapsed\n",
      "importing rows 24100000 to 24200000...Done. 4540.627218961716 total seconds elapsed\n",
      "importing rows 24200000 to 24300000...Done. 4560.4360110759735 total seconds elapsed\n",
      "importing rows 24300000 to 24400000...Done. 4580.132634878159 total seconds elapsed\n",
      "importing rows 24400000 to 24500000...Done. 4600.522381067276 total seconds elapsed\n",
      "importing rows 24500000 to 24600000...Done. 4621.574800014496 total seconds elapsed\n",
      "importing rows 24600000 to 24700000...Done. 4642.057825088501 total seconds elapsed\n",
      "importing rows 24700000 to 24800000...Done. 4663.074483156204 total seconds elapsed\n",
      "importing rows 24800000 to 24900000...Done. 4684.206156253815 total seconds elapsed\n",
      "importing rows 24900000 to 25000000...Done. 4705.909789085388 total seconds elapsed\n",
      "importing rows 25000000 to 25100000...Done. 4727.220773935318 total seconds elapsed\n",
      "importing rows 25100000 to 25200000...Done. 4748.932482242584 total seconds elapsed\n",
      "importing rows 25200000 to 25300000...Done. 4769.442985057831 total seconds elapsed\n",
      "importing rows 25300000 to 25400000...Done. 4789.9624581336975 total seconds elapsed\n",
      "importing rows 25400000 to 25500000...Done. 4810.2149431705475 total seconds elapsed\n",
      "importing rows 25500000 to 25600000...Done. 4830.282003164291 total seconds elapsed\n",
      "importing rows 25600000 to 25700000...Done. 4850.585376024246 total seconds elapsed\n",
      "importing rows 25700000 to 25800000...Done. 4870.81947016716 total seconds elapsed\n",
      "importing rows 25800000 to 25900000...Done. 4890.652288198471 total seconds elapsed\n",
      "importing rows 25900000 to 26000000...Done. 4911.28019118309 total seconds elapsed\n",
      "importing rows 26000000 to 26024289...Done. 4916.085855007172 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "# 11. Set the three variables equal to the function created in D1.\n",
    "wiki_file, kaggle_file, ratings_file = extract_transform_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Set the DataFrames from the return statement equal to the file names in Step 11. \n",
    "wiki_movies_df = wiki_file\n",
    "movies_with_ratings_df = kaggle_file\n",
    "movies_df = ratings_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
